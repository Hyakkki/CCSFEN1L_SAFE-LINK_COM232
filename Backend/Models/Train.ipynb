{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc7ba83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Logistic Regression Accuracy: 0.9275\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       500\n",
      "           1       0.94      0.86      0.90       300\n",
      "\n",
      "    accuracy                           0.93       800\n",
      "   macro avg       0.93      0.91      0.92       800\n",
      "weighted avg       0.93      0.93      0.93       800\n",
      "\n",
      "\n",
      "ðŸ”Ž Feature Importance:\n",
      "               feature  coefficient\n",
      "10      domain_length     4.078839\n",
      "13           has_http     3.099904\n",
      "5          num_params     0.860129\n",
      "1            num_dots     0.314823\n",
      "14  has_suspicious_kw     0.266311\n",
      "12          has_https     0.154435\n",
      "8         num_percent    -0.083344\n",
      "4          num_digits    -0.097778\n",
      "3              num_at    -0.172047\n",
      "11        path_length    -0.466237\n",
      "7        num_question    -0.507050\n",
      "0          url_length    -0.759001\n",
      "2         num_hyphens    -0.975982\n",
      "9         num_special    -1.287151\n",
      "6         num_slashes    -2.278590\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.parse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ========== Step 1: Load dataset ==========\n",
    "file_path = \"features_10000.csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "df = df.rename(columns={\"type\": \"label\"})\n",
    "\n",
    "# Balance dataset: 2500 benign, 1500 malicious\n",
    "benign_df = df[df[\"label\"].str.lower() == \"benign\"].head(2500)\n",
    "malicious_df = df[df[\"label\"].str.lower() == \"malicious\"].head(1500)\n",
    "sample_df = pd.concat([benign_df, malicious_df]).reset_index(drop=True)\n",
    "\n",
    "# ========== Step 2: Feature Engineering ==========\n",
    "def extract_features(url):\n",
    "    try:\n",
    "        parsed = urllib.parse.urlparse(url)\n",
    "    except:\n",
    "        parsed = None\n",
    "\n",
    "    url_length = len(url)\n",
    "    num_dots = url.count(\".\")\n",
    "    num_hyphens = url.count(\"-\")\n",
    "    num_at = url.count(\"@\")\n",
    "    num_digits = sum(c.isdigit() for c in url)\n",
    "    num_params = url.count(\"=\")\n",
    "    num_slashes = url.count(\"/\")\n",
    "    num_question = url.count(\"?\")\n",
    "    num_percent = url.count(\"%\")\n",
    "    num_special = sum(c in [';', '_', '?', '=', '&'] for c in url)\n",
    "\n",
    "    hostname = parsed.hostname if parsed and parsed.hostname else \"\"\n",
    "    domain_length = len(hostname)\n",
    "\n",
    "    path_length = len(parsed.path) if parsed and parsed.path else 0\n",
    "    has_https = 1 if parsed and parsed.scheme == \"https\" else 0\n",
    "    has_http = 1 if parsed and parsed.scheme == \"http\" else 0\n",
    "\n",
    "    keywords = [\"login\", \"secure\", \"update\", \"free\", \"verify\", \"bank\", \"account\", \"paypal\"]\n",
    "    has_suspicious_kw = any(kw in url.lower() for kw in keywords)\n",
    "\n",
    "    return [\n",
    "        url_length, num_dots, num_hyphens, num_at, num_digits,\n",
    "        num_params, num_slashes, num_question, num_percent, num_special,\n",
    "        domain_length, path_length, has_https, has_http,\n",
    "        has_suspicious_kw\n",
    "    ]\n",
    "\n",
    "# Apply feature extraction\n",
    "features = sample_df[\"url\"].apply(extract_features)\n",
    "feature_names = [\n",
    "    \"url_length\", \"num_dots\", \"num_hyphens\", \"num_at\", \"num_digits\",\n",
    "    \"num_params\", \"num_slashes\", \"num_question\", \"num_percent\", \"num_special\",\n",
    "    \"domain_length\", \"path_length\", \"has_https\", \"has_http\",\n",
    "    \"has_suspicious_kw\"\n",
    "]\n",
    "features_df = pd.DataFrame(features.tolist(), columns=feature_names)\n",
    "\n",
    "# Merge with URL + label\n",
    "final_df = pd.concat([sample_df[\"url\"].reset_index(drop=True),\n",
    "                      features_df,\n",
    "                      sample_df[\"label\"].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# ========== Step 3: Prepare Data ==========\n",
    "X = final_df.drop(columns=[\"url\", \"label\"])\n",
    "y = final_df[\"label\"].map({\"benign\": 0, \"malicious\": 1})\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ========== Step 4: Train Logistic Regression ==========\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ========== Step 5: Evaluate ==========\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"âœ… Logistic Regression Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"feature\": X.columns,\n",
    "    \"coefficient\": model.coef_[0]\n",
    "}).sort_values(by=\"coefficient\", ascending=False)\n",
    "\n",
    "print(\"\\nðŸ”Ž Feature Importance:\\n\", feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f29014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Models saved successfully!\n",
      "- logistic_model.pkl: Trained logistic regression model\n",
      "- scaler.pkl: Feature scaler\n",
      "- label_encoder.pkl: Label mapping\n",
      "\n",
      "ðŸ“Š Model Summary:\n",
      "- Training samples: 3200\n",
      "- Test samples: 800\n",
      "- Features: 15\n",
      "- Test Accuracy: 0.9275\n",
      "- Benign precision: 0.92\n",
      "- Malicious precision: 0.94\n"
     ]
    }
   ],
   "source": [
    "# ========== Step 6: Save Models ==========\n",
    "import pickle\n",
    "\n",
    "# Save the trained logistic regression model\n",
    "with open('logistic_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Save the scaler\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Save the label encoder mapping (for reference)\n",
    "label_mapping = {\"benign\": 0, \"malicious\": 1}\n",
    "with open('label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_mapping, f)\n",
    "\n",
    "print(\"âœ… Models saved successfully!\")\n",
    "print(\"- logistic_model.pkl: Trained logistic regression model\")\n",
    "print(\"- scaler.pkl: Feature scaler\")\n",
    "print(\"- label_encoder.pkl: Label mapping\")\n",
    "\n",
    "# Display model summary\n",
    "print(f\"\\nðŸ“Š Model Summary:\")\n",
    "print(f\"- Training samples: {len(X_train)}\")\n",
    "print(f\"- Test samples: {len(X_test)}\")\n",
    "print(f\"- Features: {len(feature_names)}\")\n",
    "print(f\"- Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"- Benign precision: {0.92:.2f}\")\n",
    "print(f\"- Malicious precision: {0.94:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
